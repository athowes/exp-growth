---
title: "A generative model for qPCR data"
author: "Adam Howes"
bibliography: citations.bib
output:
  html_document:
    toc: yes
    df_print: paged
abstract: |
  The purpose of this document is to specify a generative model for qPCR data which captures
  a realistic data generating process sufficiently to outperform the "standard curve" simple
  linear regression approach. We anticipate the majority of the performance benefit will
  be when there are few initial virus copies, close to the limit of detection (LOD).
---

```{r echo = FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  dpi = 320,
  out.width = "95%",
  fig.align = 'center'
)
```

\clearpage

# Introduction

<!-- * https://www.degruyter.com/document/doi/10.2202/1544-6115.1427/pdf -->
<!-- * https://sfamjournals.onlinelibrary.wiley.com/doi/epdf/10.1111/jam.14309 -->
<!-- * https://link.springer.com/content/pdf/10.1007/s00217-007-0683-z.pdf -->
<!-- * https://onlinelibrary.wiley.com/doi/epdf/10.1002/edn3.29 -->

## Background

<!-- https://www.thermofisher.com/content/dam/LifeTech/Documents/PDFs/PG1503-PJ9169-CO019879-Re-brand-Real-Time-PCR-Understanding-Ct-Value-Americas-FHR.pdf -->
<!-- https://www.gene-quantification.de/miqe-webinar-short-transcript.pdf -->

* Quantitative polymerase chain reaction (qPCR) is a technique used to detect and quantify DNA sequence concentration in a sample
* The target DNA sequence is amplified in cycles
* $C_q$ is the cycle number at which the amplification curve intersects some threshold line
* Many factors impact the absolute value of $C_q$ besides the concentration of the target DNA
* The amplification curve is determined by measuring fluorescence
* Rn is a measure of fluorescence, calculated as a ratio of the FAM dye to ROX dye
* $\Delta$Rn is Rn minus the baseline fluorescence
* Artefacts from the reaction mix or instrument can change the fluoresence measurements
* Fluorescence emission of any molecule depends on environmental factors (pH, salt concentration)

<!-- * Concentration factor -->
<!-- * Amount going in is unkown -->
<!-- * How many DNA are in a phagemid -->
<!-- * Use an electron microscope -->
<!-- * $10^8$ copies of DNA -->
<!-- * Accuracy of Nanodrop -->
<!-- * Phagemid particle -->
<!-- * Concentration in PFUs -->
<!-- * Experiment specific multiplicative units? -->
<!-- * Daisychain approach of having a relative standard -->

## The standard curve method

* Let $x$ be $\log_{10}(\text{copies per ml})$
* Carry out experiments for $x = 10^d$ where $d$ is a sequence of integers
* $C_q = a + b$
* Key relationship is that alterations of the number of copies by factors of ten should result in the same additive change in $C_q$

# Statistical model

<!-- [TODO: Let $i$ index the well position and add indexes for other relevant features (e.g. treatment)] -->

## Copy amplification

Suppose that there are initially $n_0 \in \mathbb{N}^+$ copies of the virus and the number of copies during amplification at cycle $c \in \mathbb{N}^+$ is $n_c$.
Amplification typically results in a logistic curve which may be described by parameteric models.
Two possible strategies for analysing this curve are [@ritz2008qpcr]:

1. only model the exponential component,
2. model the complete curve.

### Models for only the exponential component

First, the exponential component must be isolated.
Then, it can either be modelled deterministically or stochastically.

In the deterministic approach
$$
n_c = n_0 (1 + E)^c
$$
where $E$ is the efficiency.
The first derivative is
$$
\frac{\text{d}n_c}{\text{d}c} = n_0 \log(1 + E) (1 + E)^c
$$

In the stochastic approach, we can use a branching process model
$$
n_{c + 1} = n_c + \text{Binomial}(n_c, E)
$$
where here the efficiency $E$ must be in the range $(0, 1)$ (if $E \in \{0, 1\}$ then the model is deterministic).

### Models for the complete curve

So far, I am only aware of deterministic models for the complete curve.
Two examples are the four parameter and five parameter logistic models.

The four-parameter logistic model (4PL) is of the form
$$
n_c = n_\infty + \frac{n_0 - n_\infty}{\left(1 + (c / m)^b \right)}
$$
where $n_\infty = \lim_{t \to \infty} n_c$ is the asympotote of the curve at infinity, and $n_0 = \lim_{t \to 0} n_c$ is--in some sense--the initial number of copies, $b$ is the slope and $m$ is the cycle at which the curve passes the midpoint between $n_0$ and $n_\infty$ (I will refer to this as "the midpoint").
The first derivative of $n_c$ is
$$
\frac{\text{d}n_c}{\text{d}c} = - (n_0 - n_{\infty}) \frac{1}{\left(1 + (c / m)^b \right)^2} b \frac{c^{b - 1}}{m^b}.
$$
Evaluating this at the midpoint, $m$, gives
$$
\frac{\text{d}n_c}{\text{d}c} \rvert_{c = m} = - (n_0 - n_{\infty}) \frac{b}{4m} = \frac{(n_{\infty} - n_0)}{4m} b,
$$
such that the derivative is proportional to the slope parameter $b$.
<!-- TODO: Connect this up to the efficiency $E$. -->
<!-- Next step is to answer in which section of the logistic curve does it look like the exponential? -->

The five-parameter logistic model (5PL) includes an additional parameter $s$ which accounts for asymmetry of the curve
$$
n_c = n_\infty + \frac{n_0 - n_{\infty}}{\left(1 + (c / m)^b \right)^s}
$$

## Extension linking copies to fluorescence

We observe $(\text{Rn}_0, \ldots, \text{Rn}_C)$ where $C$ is the total number of PCR cycles run.
The number of copies $n_c$ may be connected to fluorescence data $\text{Rn}_c$ by some function $g$ such that $\text{Rn}_c \sim g(n_c)$.
It is likely sufficient to consider that this relationship is linear such that
$$
\text{Rn}_c = \alpha_0 + \alpha n_c + \epsilon_c 
$$
where $\alpha_0$ is the background fluorescence, $\alpha$ is the fluorescence produced by a single count, and $\epsilon_c$ is e.g. Gaussian noise.
qPCR machines may estimate $\alpha_0$ and provide fluoresence data with the background removed (i.e $\Delta$Rn) such that the model can be simplified to
$$
\Delta\text{Rn}_c = \alpha n_c + \epsilon_c 
$$

## Extension to stochastic cycle times

One idea for making the "deterministic" curve fitting methods more stochastic is to introduce stochastic cycle times.
Suppose that cycles $c = 1, \dots, C$ occur at times $t = t_1, \ldots, t_C$ with cycle time intervals $\kappa_c = t_{c + 1} - t_c$ between cycles.
A simple model for the intervals would be $\kappa_c \sim \mathcal{N}(\mu_\kappa, {\sigma_\kappa}^2)$.
The interval mean could be fixed to one or have a prior centered at one.
Cycle times are the cumulative sum of intervals $t_c = \sum_{d < c} \kappa_d$.

## Extension to processing

<!-- [TODO: Diagram of processing] -->

Prior to amplification, we might consider a processing step where e.g DNA is released from inside the phage capsid.
This process should likely be modelled differently depending on the copy amplification model.
Processing is more natural to include with an exponential amplification model because it is more mechanistic (it's difficult to mechanistically model the logistic curve).

### Processing with exponentation component

Suppose that a proportion $r$ of DNA are successfully released during processing from an initial number $N_0$.
Then
$$
n_0 \sim \text{Binomial}(N_0, r)
$$
where some prior could be placed on $r \sim p(r)$.

### Processing with complete curve

We could assume that reducing the initial copies of the virus by a factor of 10 increased the midpoint $m$ by one unit.
One possible way to do this is to set $\log(r) \sim \mathcal{N}^{+}(0, 1)$, then alter the midpoint such that $m \leftarrow m + \log(r)$.
This approach won't give the desired zero inflated behaviour.

<!-- ## Extension to dilution -->

<!-- TODO: Correlated dilution errors? -->

\clearpage

# Implementation

The primary aims of our analysis are:

1. To infer $N_0$ directly
2. To infer $C_q$, allowing a comparison against the value produced by default in-built software
3. To model multiple experiments jointly, eventually resulting in a posterior distribution over the standard curve
4. To appropriately deal with non-Gaussian uncertainty
For example, a property we would like to confer is inflated errors at high $C_q$ values, corresponding to low initial numbers of copies.

We will build and expand our model step-by-step using probabilistic programming languages such as Stan [@rstan] or NIMBLE [@nimble].

## Model 1: Logistic curve copy amplification, link to fluorescence

We first start by considering a model including the 4PL logistic copy amplification component linearly linked to florescence data.
The Stan code for this model is given below.
We follow a Bayesian workflow [@gelman2020bayesian] by specifying a prior, generating data from that prior, then fitting the model to the generated data.
This may be done using one Stan file by including a parameter `flag_run_estimation`.

```{r fig.cap="Prior distribution with ten samples from the prior"}
plot_prior_data_4pl
```

```{r fig.cap="Prior distribution with ten samples from the prior, and posterior distribution fitted to one sample from the prior."}
plot_prior_data_posterior_4pl
```

<!-- TODO: Suppose that we know the threshold at which $C_q$ is measured by intersection with the amplification curve. -->

\clearpage

## Model 2: Logistic curve copy amplification, link to fluoresence, processing with complete curve

The Stan code for this model is given below.

```{r fig.cap="Prior distribution with ten samples from the prior"}
plot_prior_data_4pl_processing
```

```{r fig.cap="Prior distribution with ten samples from the prior, and posterior distribution fitted to one sample from the prior."}
plot_prior_data_posterior_4pl_processing
```

\clearpage

# Model files

## Model 1 \label{sec:model1}

```{stan, echo=TRUE, eval=FALSE, output.var="ex", code=readLines('4pl/4pl.stan')}
```

## Model 2 \label{sec:model2}

```{stan, echo=TRUE, eval=FALSE, output.var="ex", code=readLines('4pl-processing/4pl-processing.stan')}
```

\clearpage

# Bibliography {-}
