---
title: "Exponential growth detection on metagenomic data"
author:
- name: Adam Howes
output:
  html_document:
    toc: yes
    df_print: paged
    code_folding: hide
abstract: |
    **Background** 
    
    **Task** 
    
    **Findings** 
    
    **Next steps** 
---

```{r setup, class.source = 'fold-hide'}
knitr::opts_chunk$set(
  echo = TRUE,
  cache = TRUE,
  autodep = TRUE,
  cache.comments = FALSE
)

options(scipen = 999)

cbpalette <- multi.utils::cbpalette()

library(tidyverse)
```

## First simulated example

We start by importing the data generated in the notebook [Simulating metagenomic time series data](https://athowes.github.io/exp-growth/metagenomic-time-series).

```{r}
df <- readRDS("depends/sample0.rds") %>%
  as_tibble()
```

This data looks as follows.

```{r}
sample_summary <- df %>%
  group_by(day, regime) %>%
  summarise(
    count_upper = quantile(count, 0.95),
    count_median = median(count),
    count_lower = quantile(count, 0.05)
  )

ggplot(sample_summary, aes(x = day, ymin = count_lower, y = count_median, ymax = count_upper, group = regime)) +
    geom_ribbon(alpha = 0.1, aes(fill = regime)) +
    geom_line(aes(col = regime), size = 1.5) +
    geom_line(data = df, aes(x = day, y = count, col = regime, group = id),
               alpha = 0.025, inherit.aes = FALSE) + 
    theme_minimal() +
    scale_color_manual(values = cbpalette) +
    scale_fill_manual(values = cbpalette) +
    guides(fill = "none") +
    labs(x = "Day", y = "Number of reads in sample", col = "Regime")
```

### Performing inference

We fit a Poisson regression model (see [Explaining Poisson regression](https://athowes.github.io/exp-growth/explain-poisson) or [Estimating exponential growth via sporadic detection](https://athowes.github.io/exp-growth/exponential-detection)) to each $k$-mer in the data.

```{r}
#' Fit to each unique id
#' Note that (confusingly) kmer is not unique, and represents the kmer within a given organism
fits <- tibble(id = unique(df$id)) %>%
  mutate(
    fit = map(id, ~glm(count ~ 1 + day, family = "poisson", data = filter(df, id == .))),
    fit = map(fit, broom::tidy, conf.int = TRUE)
  ) %>%
  unnest(fit)

#' Add truth column
fits <- fits %>%
  left_join(
    select(df, id, regime),
    by = "id"
  )
```

Now we can look at the inference for the slope parameter $\beta$ in each regression, first the point estimate with confidence interval, then the $p$-value for $\beta \neq 0$.
The truth -- either exponential or baseline regime -- is shown by the point colour.

```{r}
fits_day <- filter(fits, term == "day")

fits_day %>%
  ggplot(aes(x = id, y = estimate, ymin = conf.low, ymax = conf.high, col = regime)) +
    geom_pointrange(alpha = 0.05, size = 0.5) +
    theme_minimal() +
    scale_color_manual(values = cbpalette) +
    labs(x = "k-mer ID", y = "Estimated slope", col = "True regime") +
    theme(
      legend.position = "bottom"
    )

fits_day %>%
  ggplot(aes(x = id, y = p.value, col = regime)) +
  geom_point() +
  theme_minimal() +
  scale_color_manual(values = cbpalette) +
  labs(x = "k-mer ID", y = "p-value for positive slope", col = "True regime") +
  theme(
    legend.position = "bottom"
  )

saveRDS(fits, "fits-sample0.rds")
```

### Performance assessment

Suppose we classify as exponential growth when the 95% confidence interval for $\beta$ is above zero.
We can see which $k$-mers we misclassify by comparing this estimated regime to the true regime.

```{r}
fits_day <- fits_day %>%
  mutate(
    est_regime = case_when(
      conf.low > 0 & conf.high > 0 ~ "Exponential",
      TRUE ~ "Baseline"
    ),
    correct = case_when(
      regime == est_regime ~ TRUE,
      TRUE ~ FALSE
    )
  )

fits_day %>%
  ggplot(aes(x = id, y = estimate, ymin = conf.low, ymax = conf.high, col = correct)) +
    geom_pointrange(alpha = 0.05, size = 0.5) +
    theme_minimal() +
    scale_color_manual(values = c("#D22B2B", "grey")) +
    labs(x = "k-mer ID", y = "Estimated slope", col = "True regime") +
    theme(
      legend.position = "bottom"
    )

fits_day %>%
  ggplot(aes(x = id, y = p.value, col = correct)) +
  geom_point() +
  theme_minimal() +
    scale_color_manual(values = c("#D22B2B", "grey")) +
  labs(x = "k-mer ID", y = "p-value for positive slope", col = "True regime") +
  theme(
    legend.position = "bottom"
  )
```

All of the $k$-mers which are exponentially increasing are classified as such.
In other words, the false negative rate is zero.
There are a small number of false positives: $k$-mers in the baseline regime which are classified as exponentially increasing.

```{r}
fits_day <- fits_day %>%
  mutate(
    cm = case_when(
      regime == "Exponential" & est_regime == "Exponential" ~ "True positive",
      regime == "Exponential" & est_regime == "Baseline" ~ "False negative",
      regime == "Baseline" & est_regime == "Exponential" ~ "False positive",
      regime == "Baseline" & est_regime == "Baseline" ~ "True negative"
    )
  )

fits_day %>%
  janitor::tabyl(cm) %>%
  knitr::kable()
```

We can highlight these few false positives in a plot.

```{r}
df %>%
  left_join(
    select(fits_day, id, correct, cm),
    by = "id"
  ) %>%
  ggplot(aes(x = day, y = count, col = correct, alpha = correct, group = id)) +
    geom_line() + 
    theme_minimal() +
    scale_alpha_manual(values = c(1, 0.05)) +
    scale_color_manual(values = c("#D22B2B", "grey")) +
    guides(alpha = "none") + 
    labs(x = "Day", y = "Number of reads in sample", col = "Correctly classified?")
```

TODO: Compute classification probabilities.

The Brier score (see [Evaluating exponential growth detection](https://docs.google.com/document/d/1wSi6RknvA91mEB7gY8icdcUPHP7kEObhdwXDb5D9FAY/edit)) is given by
$$
\text{BS} = \frac{1}{n} \sum_{i = 1}^n \left(f_i - o_i \right)^2
$$
where $f_i$ is $\mathbb{P} \left[ \text{regime}(i) = 1 \right]$ and $o_i = \text{regime}(i) \in \{0, 1\}$.

### Benchmarking

We can benchmark how long the Poisson regression model takes to fit using the function `bench::mark`:

```{r}
bm <- bench::mark(
  glm(count ~ 1 + day, family = "poisson", data = filter(df, id == 1))
)

data_subset <- filter(df, id == 1)

bm2 <- bench::mark(
  glm(count ~ 1 + day, family = "poisson", data = data_subset)
) %>%
  print()

bm
bm2

saveRDS(bm, "benchmark-sample0.rds")
```

## With additional true abundance noise

```{r}
df <- readRDS("depends/sample1.rds") %>%
  as_tibble()
```

## Real data

```{r, class.source = 'fold-show'}
counts <- read.table("data/counts-1pct-sample.tsv", header = TRUE)

summary(counts)

#' There are this many k-mers in the data
nrow(counts)

#' These are the column names for counts
names(counts)

#' This is what the top part of the data looks like
head(counts)

counts_subset <- filter(counts, ec < 1000)

#' In a tidy format for plotting and fitting
counts_subset_long <- counts_subset %>%
  pivot_longer(
    cols = starts_with("day"),
    names_to = "day",
    names_prefix = "day",
    values_to = "count"
  ) %>%
  mutate(day = as.integer(day))

#' Plot the time series
ggplot(counts_subset_long, aes(x = day, y = count, group = ec)) +
  geom_line(alpha = 0.05) +
  theme_minimal() +
  labs(x = "Day", y = "Count")

#' There is also a file which I assume is the total reads
row_sums <- read.table("data/daily-counts.tsv", header = TRUE)
row_sums

counts_subset_long

#' Time per million ECs might be a useful format for benchmarking
#' Time for each of the different subsets
#' 
#' ?glm to check what the possible input formats are
#' Benchmarking the different steps (including pivot_longer)
#' Use data.table to do the pivot
#' 
#' Create egd.R that Jeff would source
#' Benchmark aspects of egd.R and try to improve the slowest running parts
#' pivoting (and other aspects) might not be linear
#' How does pivoting scale with size
#' 
#' 1. Create egd.R
#' 2. Identify steps to benchmark e.g. using profiling
#' 
#' Look at different aspects (modules) of the simulation (to have technical replicates)
#' Datasets that have that are not going to be wastewater
#' Dirichlet Multinomial maybe not as good
```


